{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7962610,
          "sourceType": "datasetVersion",
          "datasetId": 4684268
        }
      ],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "CP3403-2024-project-1",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stromrage51/CP1404_Git_Hub/blob/master/CP3403_2024_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'dataset-view:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4684268%2F7962610%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T043543Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3675215f60f3ec85be261a3d2e6248e4a63c3e842f5eea74504d7d4893f5cd1b6dd51a9f27996966df72d61a1c48f259fb1b4b5a16133ae7e7cf6cf90b7463a1776a43b736c9245e0cc0bcbdea36fec9212a6fcd170f055292e033e3854a86e10992b5ceb2994e62e34c3bc6be0a46697dec5d118be38e9a721e249cf7437317d6833627451fba3dca151bb00f5e6cc009f956e0e1bf5739e35961a3daebeaf76f18528e384966ceb5c437754f8376ec2239ebe1fef533a6209fb9ae1f0b7921a415d28540f2cb873dd47f71acc21c28b7cdd3e1e9cca94fd208de766dab7a7e5372e8e2d584b9fbe1ecfee3eb100986857ec48b1690dbefff286cfe65b3fa2f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "OJ5aYxCbgGDo"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:45.874002Z",
          "iopub.execute_input": "2024-03-29T03:47:45.874422Z",
          "iopub.status.idle": "2024-03-29T03:47:47.276203Z",
          "shell.execute_reply.started": "2024-03-29T03:47:45.874392Z",
          "shell.execute_reply": "2024-03-29T03:47:47.275217Z"
        },
        "trusted": true,
        "id": "H7Saq_XtgGDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your team\n",
        "* Matthew Ballarino"
      ],
      "metadata": {
        "id": "nFRTDp5bgGDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Dataset"
      ],
      "metadata": {
        "id": "OK5PSZwrgGDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to find your own domain-specific dataset for your data mining project. The dataset should be complex enough so that it is not straightforward to find patterns with simple calculations (impossible without preprocessing and data mining approaches). There is no limit in size for the dataset, but typically a good sized data for mining is around 100k-100M. Minimum of 100k samples/rows and minimum of 100 attributes/columns.\n",
        "\n",
        "It could have thousands/millions rows (or columns or sometimes both rows/columns). A good data typically contains various types of data (numerical, nominal, ordinal, Boolean etc) with some errors (missing or dirty values etc) in the data. The dataset could be text data, tabular formatted data, georeferenced data. See possible data sources: Kaggle repository (https://www.kaggle.com/datasets)."
      ],
      "metadata": {
        "id": "PIRnHfG-gGDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# todo: import dataset(s) into pandas and print samples.\n",
        "fpath = '/kaggle/input/dataset-view/Australia_Grocery_2022Sep.csv'\n",
        "df = pd.read_csv(fpath, header=None)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:47.280981Z",
          "iopub.execute_input": "2024-03-29T03:47:47.281624Z",
          "iopub.status.idle": "2024-03-29T03:47:52.26132Z",
          "shell.execute_reply.started": "2024-03-29T03:47:47.28158Z",
          "shell.execute_reply": "2024-03-29T03:47:52.259865Z"
        },
        "trusted": true,
        "id": "YcLCLxQlgGDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sample rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PnXvt5jkgGDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say something meaningful about your dataset. For example: Why did you select it? Is there anything interesting or special about it? What do or did hope to learn from it?\n",
        "\n",
        "The reason why Australia_Grocery_2022Sep.csv was chosen beacuse"
      ],
      "metadata": {
        "id": "vjwafr7_gGDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: business scenarios"
      ],
      "metadata": {
        "id": "oIxFRd-2gGDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List one or more possible questions you would like to investigate using your dataset. You may start this project with one set of questions but (after exploring the dataset) finish with a new set of questions and answers."
      ],
      "metadata": {
        "id": "X3_2wPPFgGDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some python code and results to support your business cases\n",
        "# df.describe(include='all')  # see prac-1."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:52.268522Z",
          "iopub.execute_input": "2024-03-29T03:47:52.268957Z",
          "iopub.status.idle": "2024-03-29T03:47:52.275759Z",
          "shell.execute_reply.started": "2024-03-29T03:47:52.268918Z",
          "shell.execute_reply": "2024-03-29T03:47:52.274138Z"
        },
        "trusted": true,
        "id": "Gn6WKC-qgGDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE! This is a data-based project. Make sure your comments are based on printed code outputs and/or graphs."
      ],
      "metadata": {
        "id": "yIVXdVMXgGDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tast-3: preprocessing"
      ],
      "metadata": {
        "id": "7Fy0HdZEgGDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See prac-2. Apply one or more preprocessing techniques"
      ],
      "metadata": {
        "id": "794xP4A_gGDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: python code with outputs\n",
        "# Add some comments to explain what and why you did.\n",
        "# NOTE! unless you have a very good reason, do not drop rows nor columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:52.277706Z",
          "iopub.execute_input": "2024-03-29T03:47:52.278069Z",
          "iopub.status.idle": "2024-03-29T03:47:52.314829Z",
          "shell.execute_reply.started": "2024-03-29T03:47:52.278041Z",
          "shell.execute_reply": "2024-03-29T03:47:52.313492Z"
        },
        "trusted": true,
        "id": "LG6OBjQBgGDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task-4: ARM"
      ],
      "metadata": {
        "id": "e60c-j8kgGDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one or more ARM techiques, see prac-3-ARM\n",
        "# Report your results based on your code output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:52.316637Z",
          "iopub.execute_input": "2024-03-29T03:47:52.317095Z",
          "iopub.status.idle": "2024-03-29T03:47:52.327735Z",
          "shell.execute_reply.started": "2024-03-29T03:47:52.317053Z",
          "shell.execute_reply": "2024-03-29T03:47:52.326533Z"
        },
        "trusted": true,
        "id": "NU0At3Y9gGDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task-5: Classification"
      ],
      "metadata": {
        "id": "KAtbRniagGDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply one or more classification methods, see pracs-4 and 5\n",
        "# Report your results based on your code output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:52.329809Z",
          "iopub.execute_input": "2024-03-29T03:47:52.330257Z",
          "iopub.status.idle": "2024-03-29T03:47:52.340123Z",
          "shell.execute_reply.started": "2024-03-29T03:47:52.33022Z",
          "shell.execute_reply": "2024-03-29T03:47:52.338847Z"
        },
        "trusted": true,
        "id": "W6OFjKAbgGDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task-6: Clustering"
      ],
      "metadata": {
        "id": "PDDBg_YOgGDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply one or more clustering methods, see pracs-6 and 7\n",
        "# Report your results based on your code output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:52.341646Z",
          "iopub.execute_input": "2024-03-29T03:47:52.342343Z",
          "iopub.status.idle": "2024-03-29T03:47:52.353045Z",
          "shell.execute_reply.started": "2024-03-29T03:47:52.342304Z",
          "shell.execute_reply": "2024-03-29T03:47:52.351847Z"
        },
        "trusted": true,
        "id": "iw57tTrbgGDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task-7: Project specific and final results"
      ],
      "metadata": {
        "id": "wDchZE9SgGDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The preceding tasks may or may not produce interesting results. They are mandatory exploration tasks.\n",
        "# In this section you need to focus on anything interesting you found so far, which is specific to your data.\n",
        "# Some additional code and output may be needed here to make any final conclusions."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T03:47:52.354943Z",
          "iopub.execute_input": "2024-03-29T03:47:52.355404Z",
          "iopub.status.idle": "2024-03-29T03:47:52.364947Z",
          "shell.execute_reply.started": "2024-03-29T03:47:52.355364Z",
          "shell.execute_reply": "2024-03-29T03:47:52.363678Z"
        },
        "trusted": true,
        "id": "zFL7l1NrgGDr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}